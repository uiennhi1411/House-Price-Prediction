{"cells":[{"cell_type":"markdown","source":["| Name                    | Huỳnh Thị Thu Thoảng |Trần Thị Uyên Nhi |Nguyễn Công Hoài Nam |Trần Tuấn Đạt |\n","|-------------------------|----------------------|----------------------|----------------------|----------------------|\n","| ID Student              | 21280074             |212800125             |21280099             |21280079             |\n","| Percent of contribution | 20%                  | 25%                  | 35%                  | 20%                  |"],"metadata":{"id":"HrW3if2_S75a"}},{"cell_type":"markdown","metadata":{"id":"e30rcGPHS0WI"},"source":["## Scraping Buying House Web"]},{"cell_type":"markdown","metadata":{"id":"R_l0GgyQS0WN"},"source":["### Import Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QUsWqL5sS0WO"},"outputs":[],"source":["from bs4 import BeautifulSoup\n","import urllib.request\n","import requests\n","import re"]},{"cell_type":"markdown","metadata":{"id":"pRCvjdVYS0WR"},"source":["### Scraping"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BpcsiPaCS0WS"},"outputs":[],"source":["def download_html(url):\n","    with urllib.request.urlopen(url) as response:\n","        html = response.read()\n","        html = html.decode('utf-8')\n","    response.close()\n","    return html"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RE4fEKhqS0WT"},"outputs":[],"source":["def scrape_block(buying_house_blocks):\n","    try:\n","        url = buying_house_blocks.find('a').get('href')\n","        source = download_html(url)\n","    except:\n","        source = ''\n","    soup = BeautifulSoup(source, 'lxml') #html.parser\n","    info_custom = soup.find('div',{'class':'project-global-object-block-003 information-custom'})\n","    block_custom = soup.find('div',{'class':'project-global-object-block-003 block-custom'})\n","    uk_breadcrumb = soup.find('ul',{'class':'uk-breadcrumb'})\n","    buying_house_data ={}\n","\n","    try:\n","        buying_house_data['datetime'] = info_custom.find('time',{'class':'timeago'}).get('datetime')\n","    except:\n","        buying_house_data['datetime'] = None\n","\n","    try:\n","        buying_house_data['title'] = info_custom.find('h1').get_text()\n","    except:\n","        buying_house_data['title'] = None\n","\n","    try:\n","        buying_house_data['link'] = buying_house_blocks.find('a').get('href')\n","    except:\n","        buying_house_data['link'] = None\n","\n","    try:\n","        breadcrumb = uk_breadcrumb.findAll('a')\n","        buying_house_data['house_type'] = re.split('Bán\\s+',breadcrumb[1].get_text())[1]\n","    except:\n","        buying_house_data['house_type'] = None\n","\n","    try:\n","        price = info_custom.find('strong',{'class':'price'}).get_text().strip()\n","        buying_house_data['price'] = price\n","    except:\n","        buying_house_data['price'] = None\n","\n","    try:\n","        text = r'Diện tích:'\n","        element = info_custom.find(lambda tag: tag.name == \"strong\" and text in tag.text)\n","        buying_house_data['acreage'] = element.next_sibling.get_text().strip()\n","    except:\n","        buying_house_data['acreage'] = None\n","\n","    try:\n","        text = r'Địa chỉ:'\n","        element = info_custom.find(lambda tag: tag.name == \"strong\" and text in tag.text)\n","        buying_house_data['address'] = element.next_sibling.get_text().strip()\n","    except:\n","        buying_house_data['address'] = None\n","\n","    try:\n","        breadcrumb = uk_breadcrumb.findAll('a')\n","        district = breadcrumb[3].get_text()\n","        buying_house_data['district'] = district\n","    except:\n","        buying_house_data['district'] = None\n","\n","    try:\n","        breadcrumb = uk_breadcrumb.findAll('a')\n","        city = breadcrumb[2].get_text()\n","        buying_house_data['city'] = city\n","    except:\n","        buying_house_data['city'] = None\n","\n","    try:\n","        text = r'Phòng ngủ:'\n","        element = info_custom.find(lambda tag: tag.name == \"strong\" and text in tag.text)\n","        buying_house_data['bedrooms'] = element.next_sibling.get_text().strip()\n","    except:\n","        buying_house_data['bedrooms'] = None\n","\n","    try:\n","        text = r'Phòng WC:'\n","        element = info_custom.find(lambda tag: tag.name == \"strong\" and text in tag.text)\n","        buying_house_data['wc'] = element.next_sibling.get_text().strip()\n","    except:\n","        buying_house_data['wc'] = None\n","\n","    try:\n","        text = r'Hướng nhà:'\n","        element = info_custom.find(lambda tag: tag.name == \"strong\" and text in tag.text)\n","        buying_house_data['house_direction'] = element.next_sibling.get_text().strip()\n","    except:\n","        buying_house_data['house_direction'] = None\n","\n","    try:\n","        text = r'Hướng ban công:'\n","        element = info_custom.find(lambda tag: tag.name == \"strong\" and text in tag.text)\n","        buying_house_data['balcony_direction'] = element.next_sibling.get_text().strip()\n","    except:\n","        buying_house_data['balcony_direction'] = None\n","\n","    try:\n","        buying_house_data['description'] = block_custom.find('p').get_text()\n","    except:\n","        buying_house_data['description'] = None\n","\n","    return buying_house_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hG-ll0LQS0WX"},"outputs":[],"source":["def scrape_page(buying_house_blocks):\n","\n","    page_buying_house_data = []\n","    num_blocks = len(buying_house_blocks)\n","\n","    for block in range(num_blocks):\n","        page_buying_house_data.append(scrape_block(buying_house_blocks[block]))\n","\n","    return page_buying_house_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lHfh4TkGS0WY"},"outputs":[],"source":["import time\n","import random as ran\n","def scrape_this(link,start,end):\n","\n","    #from IPython.core.debugger import set_trace\n","\n","    base_url = link\n","\n","    page_number = start\n","\n","    buying_house_data = []\n","    while page_number <= end:\n","\n","        url = base_url + str(page_number)\n","\n","        #set_trace()\n","\n","        source = download_html(url)\n","        soup = BeautifulSoup(source, 'lxml') # lxml\n","\n","        buying_house_blocks = (soup.find('div',{'class':'project-global-object-block-002 realestate-post-list-custom block-custom'})).findAll('div',{'class':'name'})\n","\n","        buying_house_data.extend(scrape_page(buying_house_blocks))\n","\n","\n","        print('\\r' + \"currently scraping movies from: \" + str(page_number) + \" - \"+str(end), \"| remaining count: \" + str(end-page_number), flush=True, end =\"\\n\")\n","\n","        page_number+=1\n","\n","        time.sleep(ran.randint(0, 10))\n","\n","    return buying_house_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PsT1F7zQS0Wa"},"outputs":[],"source":["import pandas as pd\n","base_scraping_link = \"https://batdongsan.vn/ban-nha/p\"\n","\n","start = 1\n","end = 100\n","buying_houses = []\n","\n","buying_houses = scrape_this(base_scraping_link,int(start),int(end))\n","\n","print('\\r'+\"List of \" + str(start) + \"-\" + str(end),\"pages of buying houses:\" + \"\\n\", end= \"\")\n","buying_houses=pd.DataFrame(buying_houses)\n","buying_houses.head()\n"]},{"cell_type":"markdown","metadata":{"id":"rkE2792HS0Wa"},"source":["Writing to csv for next steps"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vitCzyQjS0Wb"},"outputs":[],"source":["buying_houses.to_csv('merged_data.csv', encoding='utf-8-sig', index = False)\n"]},{"cell_type":"markdown","metadata":{"id":"-O-BVCoES0Wc"},"source":["## Preliminar Data Engineering for the data extracted by web crawler\n","\n"]},{"cell_type":"markdown","metadata":{"id":"YtgJuoYrS0Wd"},"source":["### Import libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pTz4YxpsS0Wd"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import re\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ob2W-D0MS0We"},"outputs":[],"source":["merged_data = pd.read_csv('merge_data.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OP9ywlC5S0We"},"outputs":[],"source":["data = merged_data.copy()"]},{"cell_type":"markdown","metadata":{"id":"ev-dvioQS0Wf"},"source":["### Some functions used for data processing"]},{"cell_type":"markdown","metadata":{"id":"jiF_ffCzS0Wf"},"source":["Convert string to number"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xB2LQzPCS0Wg"},"outputs":[],"source":["def convert_string_to_number(string):\n","    # Tạo từ điển ánh xạ chữ thành số\n","    number_mapping = {\n","        'một': 1,\n","        'hai': 2,\n","        'ba': 3,\n","        'bốn' : 4,\n","        'năm' : 5,\n","        'sáu' : 6,\n","        'bảy' : 7,\n","        'tám' : 8,\n","        'chín' : 9,\n","        'mười' : 10\n","    }\n","\n","    # Tách chuỗi thành các từ riêng lẻ\n","    words = string.lower().split()\n","\n","    # Thay thế các từ chữ thành số theo từ điển ánh xạ\n","    converted_words = [str(number_mapping[word]) if word in number_mapping else word for word in words]\n","\n","    # Kết hợp các từ thành chuỗi kết quả\n","    converted_string = ' '.join(converted_words)\n","\n","    return converted_string\n"]},{"cell_type":"markdown","metadata":{"id":"hGpQYcMjS0Wh"},"source":["Find number of floors and convert to float"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NLs1daK3S0Wh"},"outputs":[],"source":["\n","def find_floors(text):\n","    string = re.search('\\d+\\s*(?:tầng|Tầng|Tầng|TẦNG|Lầu|lầu|LẦU)',convert_string_to_number(text))\n","    if string:\n","        increment = re.search('\\d+\\s*(?:Lầu|lầu|LẦU)',string.group())\n","        if increment:\n","            result = re.sub(r'[^\\d]', '', increment.group()) # cộng 1 tầng trệt\n","            result = int(str(int(result)+1))\n","        else:\n","            result = re.sub(r'[^\\d]', '', string.group())\n","    else:\n","        result = re.findall('(?:tầng|Tầng|Tầng|TẦNG|Lầu|lầu|LẦU)\\s*\\d+',convert_string_to_number(text))\n","        if result:\n","            result = int(re.sub(r'[^\\d]', '', result[-1]))\n","        else:\n","            return None\n","    return float(result)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8oK77CAXS0Wi","outputId":"948187af-3410-41b4-ab61-f862e70ca384"},"outputs":[{"data":{"text/plain":["2.0"]},"execution_count":77,"metadata":{},"output_type":"execute_result"}],"source":["text = 'một trệt một lầu'\n","find_floors(text)"]},{"cell_type":"markdown","metadata":{"id":"1iy_knbqS0Wk"},"source":["Find price in some text data like `title`, `description` and convert to float"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"koYKXqiqS0Wo"},"outputs":[],"source":["import re\n","def convert_price_to_number(text):\n","    # Tìm và trích xuất các phần số từ chuỗi\n","    matches = re.findall('\\d+\\s*(?:tỷ|Tỷ|TỶ|tỉ|TỈ|Tỉ|T\\s|Ty|ty|tyy|tyy)(?:\\s\\d+|\\d+)(?:\\striệu|\\sTriệu|\\sTRIỆU|\\str|triệu|Triệu|TRIỆU|Trieu|trieu|tr)?', convert_string_to_number(text))\n","    if matches:\n","        matches = re.findall('\\d+', matches[-1])\n","        result = float('.'.join(matches))\n","    else:\n","        matches = re.findall('(?:\\d+|\\d+(?:\\.|,)\\s*(?:\\w+|\\d+\\s))\\s*(?:tỷ|Tỷ|TỶ|tỉ|TỈ|Tỉ|T\\s|triệu|Triệu|TRIỆU|trieu|Trieu|tr\\s|Ty\\s|ty\\s|Tyy\\s|tyy\\s)', convert_string_to_number(text))\n","        if matches:\n","            result = re.sub(',', '.', matches[-1])\n","            result = re.sub('(?:\\d+|\\d+(?:\\.|,)\\s*(?:\\w+|\\d+\\s))\\s*(?:triệu|Triệu|TRIỆU|trieu|Trieu|tr)', lambda x: str(float(re.findall('\\d+(?:\\.\\d+)?', x.group(0))[-1])/1000), result)\n","            result = float(re.sub('[^\\d\\.,]','',result))\n","        else:\n","            return None\n","    return float(result)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V-x0S93SS0Wp","outputId":"7545912e-da0d-41b0-a63a-10ce30474214"},"outputs":[{"data":{"text/plain":["5.2"]},"execution_count":79,"metadata":{},"output_type":"execute_result"}],"source":["text = '5ty200 triệu'\n","convert_price_to_number(text)"]},{"cell_type":"markdown","metadata":{"id":"_ifElbcjS0Wq"},"source":["Calculate proverty age"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RudeWBE_S0Wr"},"outputs":[],"source":["from datetime import datetime\n","\n","def calculate_property_age(listing_date_str):\n","    # Convert the listing date string to a datetime object\n","    listing_date = datetime.strptime(listing_date_str, \"%Y-%m-%d %H:%M:%S\")\n","\n","    # Get the current date and time\n","    current_date = datetime.now()\n","\n","    # Calculate the age of the property\n","    age = current_date - listing_date\n","    age_in_years = age.days\n","\n","    return age_in_years"]},{"cell_type":"markdown","metadata":{"id":"NpxthiQ2S0Wr"},"source":["Processing Address"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tct5ao3aS0Ws"},"outputs":[],"source":["def is_substring(string1, string2):\n","    return string1.lower() in string2.lower()\n","\n","###\n","\n","def process_address(address, district, city):\n","    if address is None or len(address.strip()) == 0:\n","        return district + ', ' + city\n","    elif is_substring(district,address):\n","        if is_substring(city,address):\n","            return address\n","        else:\n","            return address + ', ' + city\n","    else:\n","        return address + ', ' + district + ', ' + city\n"]},{"cell_type":"markdown","metadata":{"id":"s--csKHPS0Ws"},"source":["Get coordinates with longitude and latitude"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-cDUNQi5S0Wt"},"outputs":[],"source":["from geopy.geocoders import Nominatim\n","from geopy.extra.rate_limiter import RateLimiter\n","\n","def get_coordinates(address, district, city):\n","    geolocator = Nominatim(user_agent='my_app')\n","    geocode_with_limiter = RateLimiter(geolocator.geocode, min_delay_seconds=1)\n","\n","    location = geocode_with_limiter(address, limit = 1)\n","\n","    if location is not None:\n","        return location.latitude, location.longitude\n","    else:\n","        address = district + ', ' + city\n","        location = geocode_with_limiter(address, limit= 1 )\n","\n","        if location is not None:\n","            return location.latitude, location.longitude\n","        else:\n","            return None, None\n"]},{"cell_type":"markdown","metadata":{"id":"dka0SThfS0Wt"},"source":["Find `place_type` such as: hospital, school, etc near house"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SSrsKGSkS0Wu"},"outputs":[],"source":["from geopy.geocoders import Nominatim\n","from geopy.extra.rate_limiter import RateLimiter\n","from geopy.distance import geodesic\n","\n","def is_nearby_places(latitude, longitude, place_type, radius):\n","    geolocator = Nominatim(user_agent='my_app')\n","    geocode_with_limiter = RateLimiter(geolocator.geocode, min_delay_seconds=1)\n","\n","    location = geolocator.reverse((latitude, longitude), exactly_one=True)\n","    address = location.address\n","\n","    # Tìm kiếm các tiện ích gần tọa độ\n","    query = place_type + \" near \" + address\n","    geocode = geocode_with_limiter(query, exactly_one=False, limit=None)\n","\n","    if geocode is not None:\n","        for place in geocode:\n","            place_latitude = place.latitude\n","            place_longitude = place.longitude\n","\n","            distance = geodesic((latitude, longitude), (place_latitude, place_longitude)).meters\n","            if distance <= radius:\n","                return distance\n","\n","    return None\n"]},{"cell_type":"markdown","metadata":{"id":"2JGBbi3bS0Wv"},"source":["## Data Processing"]},{"cell_type":"markdown","metadata":{"id":"nE8LrCPAS0Ww"},"source":["Convert certain columns like `acreage` and `price` from strings to number, and make them uniform"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WdP_Amr5S0Ww"},"outputs":[],"source":["data.fillna(\"\", inplace = True)\n","##\n","data['address'] = data.apply(lambda x: process_address(x['address'],x['district'],x['city']),axis =1)\n","##\n","data['price'] = data['price'].apply(lambda x: re.sub(r'(\\d+\\.\\d+|\\d+)\\s*triệu', lambda y: str(float(y.group(1))/1000) + ' tỷ',x))\n","data['price'] = data['price'].apply(lambda x: re.sub('[^\\d.]','',x))\n","##\n","data['acreage'] = data['acreage'].apply(lambda x: re.sub(r'[^0-9.]', '', x))\n","##\n","data['bedrooms'] = data['bedrooms'].apply(lambda x: re.sub(r'[^\\d]', '', x))\n","##\n","data['wc'] = data['wc'].apply(lambda x: re.sub(r'[^\\d]', '', x))\n"]},{"cell_type":"markdown","metadata":{"id":"UHo1LAG2S0Wx"},"source":["Find new data from `title` and `description` to fill missing and anomalous data using regex"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"51DvDI5JS0Wy"},"outputs":[],"source":["data['price 2'] = data['title'].apply(lambda x: convert_price_to_number(x))\n","##\n","data['price 3'] = data['description'].apply(lambda x: convert_price_to_number(x))\n","##\n","data['wc 2'] = data['description'].apply(lambda x: re.search('\\d+\\s*(?:WC|wc|Wc|Nhà vệ sinh|nhà vệ sinh|Vệ sinh|vệ sinh|Toilet|toilet)',convert_string_to_number(x)))\n","data['wc 2'] = data['wc 2'].apply(lambda x: x.group() if x else None)\n","data['wc 2'].fillna('', inplace=True)\n","data['wc 2'] = data['wc 2'].apply(lambda x: re.sub(r'[^\\d]', '', x))\n","#\n","data['bedrooms 2'] = data['description'].apply(lambda x: re.search('\\d+\\s*(?:PN|pn|Pn|pngu|Pngu|Phòng ngủ|phòng ngủ|PHÒNG NGỦ|Phòng Ngủ|ngủ|Ngủ|NGỦ)',convert_string_to_number(x)))\n","data['bedrooms 2'] = data['bedrooms 2'].apply(lambda x: x.group() if x else None)\n","data['bedrooms 2'].fillna('', inplace=True)\n","data['bedrooms 2'] = data['bedrooms 2'].apply(lambda x: re.sub(r'[^\\d]', '', x))\n","##\n","data['floors'] = data['description'].apply(lambda x: find_floors(x))\n","##\n","data['floors 2'] = data['title'].apply(lambda x: find_floors(x))\n","##\n","data['property age'] = data['datetime'].apply(lambda x: calculate_property_age(x))\n","##\n","data['latitude'], data['longitude'] = zip(*data.apply(lambda x: get_coordinates(x['address'], x['district'], x['city']), axis=1))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HuKmcFQDS0W1"},"outputs":[],"source":["# Lọc các hàng có giá trị null trong cột 'latitude' và 'longitude'\n","null_rows = data[data['latitude'].isnull() | data['longitude'].isnull()]\n","\n","# Điền giá trị null trong cột 'latitude' và 'longitude' bằng cách gọi hàm get_coordinates\n","for index, row in null_rows.iterrows():\n","    latitude, longitude = get_coordinates(row['address'], row['district'], row['city'])\n","    data.at[index, 'latitude'] = latitude\n","    data.at[index, 'longitude'] = longitude"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Az7g-w9yS0W2"},"outputs":[],"source":["# Tìm hàng có latitude = 13.7989967 và longitude = 100.5491731\n","row_index = data[(data['latitude'] == 13.7989967) & (data['longitude'] == 100.5491731)].index #coordiate wrong thailand\n","\n","# Chỉnh sửa giá trị longitude và latitude\n","data.loc[row_index, 'longitude'] = 105.8300542\n","\n","data.loc[row_index, 'latitude'] = 21.015036"]},{"cell_type":"markdown","metadata":{"id":"qRI6sbIvS0W3"},"source":["Find `place_type` near house and return True/False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FZSuzFJhS0W4"},"outputs":[],"source":["import time\n","\n","radius = 1000\n","\n","place_type = 'hospital'\n","try:\n","    data[place_type] = data.apply(lambda row: is_nearby_places(row['latitude'], row['longitude'], place_type, radius), axis=1)\n","except Exception as e:\n","    print(f\"Error occurred when finding nearby {place_type}: {str(e)}\")\n","    time.sleep(1)\n","    data[place_type] = data.apply(lambda row: is_nearby_places(row['latitude'], row['longitude'], place_type, radius), axis=1)\n","\n","place_type = 'supermarket'\n","try:\n","    data[place_type] = data.apply(lambda row: is_nearby_places(row['latitude'], row['longitude'], place_type, radius), axis=1)\n","except Exception as e:\n","    print(f\"Error occurred when finding nearby {place_type}: {str(e)}\")\n","    time.sleep(1)\n","    data[place_type] = data.apply(lambda row: is_nearby_places(row['latitude'], row['longitude'], place_type, radius), axis=1)\n","\n","place_type = 'school'\n","try:\n","    data[place_type] = data.apply(lambda row: is_nearby_places(row['latitude'], row['longitude'], place_type, radius), axis=1)\n","except Exception as e:\n","    print(f\"Error occurred when finding nearby {place_type}: {str(e)}\")\n","    time.sleep(1)\n","    data[place_type] = data.apply(lambda row: is_nearby_places(row['latitude'], row['longitude'], place_type, radius), axis=1)\n","\n","place_type = 'park'\n","try:\n","    data[place_type] = data.apply(lambda row: is_nearby_places(row['latitude'], row['longitude'], place_type, radius), axis=1)\n","except Exception as e:\n","    print(f\"Error occurred when finding nearby {place_type}: {str(e)}\")\n","    time.sleep(1)\n","    data[place_type] = data.apply(lambda row: is_nearby_places(row['latitude'], row['longitude'], place_type, radius), axis=1)\n"]},{"cell_type":"code","source":[],"metadata":{"id":"e56uFE9ZTlHB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["columns = ['hospital_distance','supermarket_distance','school_distance','park_distance']\n","for col in columns:\n","  df[col] = df[col].replace(0, 10000)"],"metadata":{"id":"dBJBzIYg566w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Tìm hàng có latitude = 13.7989967 và longitude = 100.5491731\n","row_index = df[(df['latitude'] == 13.7989967) & (df['longitude'] == 100.5491731)].index\n","#coordiate wrong thailand\n","df.loc[row_index, 'longitude'] = 105.8300542\n","\n","df.loc[row_index, 'latitude'] = 21.015036"],"metadata":{"id":"eS49afQegVF0"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-7iAozzAS0W6"},"outputs":[],"source":["# Tạo cột 'amenities_rating' ban đầu với giá trị mặc định là 0\n","data['amenities_rating'] = 0\n","\n","# Đánh giá mức độ tiện nghi dựa trên các cột tiện ích\n","data.loc[data['hospital'], 'amenities_rating'] += 2\n","data.loc[data['school'], 'amenities_rating'] += 1\n","data.loc[data['supermarket'], 'amenities_rating'] += 1\n","data.loc[data['park'], 'amenities_rating'] += 1"]},{"cell_type":"markdown","metadata":{"id":"mRmbgAnzS0W7"},"source":["Fill data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-V2Ab3hTS0W8"},"outputs":[],"source":["data.replace(\"\", np.nan, inplace=True)\n","\n","data['acreage'] = data['acreage'].astype(float)\n","\n","data['bedrooms'] = data['bedrooms'].fillna(data['bedrooms 2'])\n","\n","data['wc'] = data['wc'].fillna(data['wc 2'])\n","\n","data['floors'] = data['floors'].fillna(data['floors 2'])\n","data['price 2'] = data['price 2'].fillna(data['price 3'])\n","data['price'] = data['price'].fillna(data['price 2']).astype(float)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NsJfeUd-S0W9"},"outputs":[],"source":["# Convert the columns to their proper data types\n","data = data.astype(dtype={'price':float,'acreage':float,'bedrooms':float,'wc':float,'floors':float})"]},{"cell_type":"markdown","metadata":{"id":"VBJ4NbrAS0W-"},"source":["Writing to csv files for next steps"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jKKSmMr8S0W-"},"outputs":[],"source":["data.drop(columns=['title','description','house_direction','balcony_direction','link'], inplace=True)\n","data.to_csv('output.csv',encoding='utf-8-sig',index=False)\n","os.startfile('output.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UTBmuVLdS0W_","outputId":"3932e767-a94e-4c0f-f135-5b96ad940aca"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 9721 entries, 0 to 9720\n","Data columns (total 23 columns):\n"," #   Column            Non-Null Count  Dtype  \n","---  ------            --------------  -----  \n"," 0   datetime          9721 non-null   object \n"," 1   house_type        9721 non-null   object \n"," 2   price             9613 non-null   float64\n"," 3   acreage           8933 non-null   float64\n"," 4   address           9721 non-null   object \n"," 5   district          9721 non-null   object \n"," 6   city              9721 non-null   object \n"," 7   bedrooms          7725 non-null   float64\n"," 8   wc                6622 non-null   float64\n"," 9   price 2           8755 non-null   float64\n"," 10  price 3           6876 non-null   float64\n"," 11  wc 2              3629 non-null   float64\n"," 12  bedrooms 2        5740 non-null   float64\n"," 13  floors            7720 non-null   float64\n"," 14  floors 2          3764 non-null   float64\n"," 15  property age      9721 non-null   int64  \n"," 16  latitude          9721 non-null   float64\n"," 17  longitude         9721 non-null   float64\n"," 18  hospital          9721 non-null   bool   \n"," 19  supermarket       9721 non-null   bool   \n"," 20  school            9721 non-null   bool   \n"," 21  park              9721 non-null   bool   \n"," 22  amenities_rating  9721 non-null   int64  \n","dtypes: bool(4), float64(12), int64(2), object(5)\n","memory usage: 1.4+ MB\n"]}],"source":["data.info()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"},"orig_nbformat":4,"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}